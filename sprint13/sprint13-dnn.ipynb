{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNNスクラッチコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNNとは\n",
    "\n",
    "DeepNeuralNetwork(DNN)とはニューラルネットワークを文字通りdeepに(深く)したものです。\n",
    "ニューラルネットワークが３層（入力層、隠れ層、出力層）だったのに対し、DNNは隠れ層が４つ以上のものを指します。\n",
    "\n",
    "非線形関数を組み合わせることで表現力を高めることが\n",
    "\n",
    "また層を深くすることでメリットだけでなく**勾配爆発/消失、過学習**といった問題が発生する恐れもあります。\n",
    "\n",
    "- 勾配爆発\n",
    "\n",
    "- 勾配消失\n",
    "    - バックプロパゲーションで勾配を求める際を考える。計算グラフで乗算ノードとなる層（全結合層、畳み込み層など）が複数層ある場合、勾配の値は基本的に-1から1の間の値を取るため前の層に行くほど小さくなってしまう。つまり前の層ほど学習スピードが遅くなってしまう。\n",
    "\n",
    "- 過学習\n",
    "    - 層を深くすることで表現力が増すため、学習データに対する精度はどんどん上がっていきます。これが行き過ぎると学習データに最適化されすぎて未学習のデータに対する精度が下がってしまう。このように特定のデータにだけ性能が高く、汎化性能が落ちることを**過学習**と呼びます。\n",
    "    \n",
    "    \n",
    "DNNを構築する際は上記のような問題に対処できるような工夫（ReLUを使う、正則化項）や機能層（ドロップアウト、バッチノーマリゼーション）を採用する必要がります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データのロード\n",
    "\n",
    "mnistの手書き文字認識問題\n",
    "\n",
    "784ピクセルの値（0-255）から数字（0-9）を分類する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\", nrows=1000)\n",
    "# train_df = pd.read_csv(\"train.csv\")\n",
    "# test_df = pd.read_csv(\"test.csv\", nrows=100)\n",
    "\n",
    "X = train_df.drop('label', axis=1)\n",
    "y = pd.get_dummies(train_df['label'])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# 訓練とテストデータに分割\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 活性化関数を用意\n",
    "\n",
    "シグモイド\n",
    "\n",
    "ReLU\n",
    "\n",
    "tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(z):\n",
    "#      return 1/(1+np.exp(-z))\n",
    "    \n",
    "# def ReLU(z):\n",
    "#     a = z.copy()\n",
    "#     a[a<0]=0\n",
    "#     return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力関数　ソフトマックス関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コスト関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, y_pred):\n",
    "    \n",
    "    data_size = y.shape[0]\n",
    "\n",
    "    # クロスエントロピー誤差関数　y_predは０になりえるので -inf にならないためにすごく小さい補正値を入れる\n",
    "    cross_entorpy = -np.sum(y * np.log(y_pred + 1e-7))\n",
    "    \n",
    "    error = cross_entorpy  / data_size\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cost(y, y_pred, params, lam=0.01):\n",
    "#     data_size = y.shape[0]\n",
    "#     #  正則化項\n",
    "#     weight_sum = sum([np.sum(matrix**2) for key, matrix in params.items() if \"W\" in key])\n",
    "#     reg_term = (lam /2) * (weight_sum)\n",
    "#     # クロスエントロピー誤差関数　y_predは０になりえるので -inf にならないためにすごく小さい補正値を入れる\n",
    "#     cross_entorpy = -np.sum(y * np.log(y_pred + 1e-7))\n",
    "    \n",
    "#     cost = (cross_entorpy + reg_term) / data_size\n",
    "#     return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正答率を算出する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 正答率を算出する\n",
    "# def accuracy_score(X, y, params):\n",
    "#     y_pred =  predict(X, params)\n",
    "#     y_pred_number = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "#     y_label = np.argmax(y, axis=1)\n",
    "    \n",
    "#     data_size = X.shape[0]\n",
    "    \n",
    "#     correct_count = np.sum([y_label == y_pred_number]) \n",
    "#     score = correct_count / data_size * 100\n",
    "    \n",
    "#     return round(score, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 損失関数\n",
    "        self.y = None       # softmaxの出力\n",
    "        self.t = None       # 教師データ（one-hot vector)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size # delta3に相当\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アフィン変換層\n",
    "\n",
    "更新手法をsgd,adagrad,adamと切り替えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b, params= {'optimizer': 'sgd', 'lr': 0.01}):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        # パラメータの微分値\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        # optimizerのスイッチング\n",
    "        # optimizeメソッドを付け替える\n",
    "        if params['optimizer']=='sgd':\n",
    "            self.optimize = self.update_sgd\n",
    "        elif params['optimizer'] == 'adagrad':\n",
    "            self.h = np.zeros_like(W)\n",
    "            self.optimize = self.update_adagrad\n",
    "        else: # params['optimizer'] == 'adam':\n",
    "            self.m = np.zeros_like(W)\n",
    "            self.v = np.zeros_like(W)\n",
    "            self.beta1 = 0.9\n",
    "            self.beta2 = 0.999\n",
    "            self.optimize = self.update_adam\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "    def update_sgd(self):\n",
    "        self.W -= self.lr * self.dW\n",
    "        self.b -= self.lr * self.db\n",
    "    \n",
    "    # adagrad 少しずつ更新量が減っていく\n",
    "    def update_adagrad(self):\n",
    "        self.h += self.dW ** 2\n",
    "        self.W -= self.lr * self.dW / (np.sqrt(self.h) + 1e-7)\n",
    "        self.b -= self.lr * self.db\n",
    "        \n",
    "    \n",
    "    def update_adam(self):\n",
    "        self.m = self.beta1 * self.m + (1- self.beta1) * self.dW\n",
    "        self.v = self.beta2 * self.v + (1- self.beta2) * (self.dW * self.dW)\n",
    "        \n",
    "        m_hat = self.m / (1 - self.beta1)\n",
    "        v_hat = self.v / (1 - self.beta2)\n",
    "        \n",
    "        self.W -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n",
    "        self.b -= self.lr * self.db\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 活性化関数層\n",
    "\n",
    "活性化関数層には以前作成したReLU、tanh,シグモイド関数を切り替えて使用できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    '''\n",
    "    活性化関数を設定できる \n",
    "    'tanh'\n",
    "    'sigmoid'\n",
    "    'relu'\n",
    "    '''\n",
    "    def __init__(self, params):\n",
    "        self.out = None\n",
    "        self.mask = None\n",
    "        if params['act_func']=='tanh':\n",
    "            self.forward = self.forward_tanh\n",
    "            self.backward = self.backward_tanh\n",
    "        elif params['act_func'] == 'sigmoid':\n",
    "            self.forward = self.forward_sigmoid\n",
    "            self.backward = self.backward_sigmoid\n",
    "        else: # params['act_func'] == 'relu':\n",
    "            self.forward = self.forward_relu\n",
    "            self.backward = self.backward_relu\n",
    "     \n",
    "    def forward_relu(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward_relu(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx\n",
    "\n",
    "    # tanh \n",
    "    def forward_tanh(self, x):\n",
    "        out = np.tanh(x)\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward_tanh(self, dout):\n",
    "        dx = dout * (1 - np.tanh(dout)**2)\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "    # sigmoid関数\n",
    "    def forward_sigmoid(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward_sigmoid(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        \n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチノーマリゼーション層\n",
    "\n",
    "Batch Normalization層とはフィーチャースケーリングを行うことで\n",
    "\n",
    "効果として、\n",
    "\n",
    "- 学習速度を早める\n",
    "- 初期値にそれほど依存しない\n",
    "- 過学習を抑制する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm:\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.out = None\n",
    "        self.beta = 0.0\n",
    "        self.gamma = 1.0\n",
    "        self.lr =lr\n",
    "        self.eps = 1e-8\n",
    "    \n",
    "    '''\n",
    "    計算式は下記を参照\n",
    "    https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        data_size, input_size = x.shape\n",
    "        \n",
    "        # 単に標準化する\n",
    "        # out = (x - np.mean(x, axis=0)) / np.var()\n",
    "        \n",
    "        # step1: 平均を求める\n",
    "        mu = np.mean(x, axis=0)\n",
    "        \n",
    "        # step2: 偏差\n",
    "        self.xmu = x - mu\n",
    "        \n",
    "        # step3 : 偏差の２乗\n",
    "        sq = self.xmu ** 2\n",
    "        \n",
    "        # step4 : 分散を求める\n",
    "        self.var = np.var(x, axis=0)\n",
    "        \n",
    "        # step5 : 分散のルートを取った値を求める\n",
    "        self.sqrtvar = np.sqrt(self.var + self.eps)\n",
    "        \n",
    "        # step6 : sqrtvarの逆数（invert）\n",
    "        self.ivar = 1.0/ self.sqrtvar\n",
    "        \n",
    "        # step7 : 標準化した値\n",
    "        self.xhat = self.xmu * self.ivar\n",
    "        \n",
    "        # step8\n",
    "        gammax = self.gamma * self.xhat\n",
    "        \n",
    "        # step9\n",
    "        out = gammax + self.beta\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        #get the dimensions of the input/output\n",
    "        N, D = dout.shape\n",
    "        \n",
    "        # step9\n",
    "        self.d_beta = np.sum(dout, axis=0)\n",
    "        dgammax = dout #not necessary, but more understandable\n",
    "        \n",
    "        # step8\n",
    "        self.d_gamma = np.sum(dgammax*self.xhat, axis=0)\n",
    "        dxhat = self.d_gamma * self.gamma\n",
    "        \n",
    "        # step7\n",
    "        divar = np.sum(dxhat*self.xmu, axis=0)\n",
    "        dxmu1 = dxhat * self.ivar\n",
    "        \n",
    "        # step6\n",
    "        dsqrtvar = -1. /(self.sqrtvar**2) * divar\n",
    "        \n",
    "        # step5\n",
    "        dvar = 0.5 * 1. / np.sqrt(self.var+self.eps) * dsqrtvar\n",
    "        \n",
    "        # step4\n",
    "        dsq = 1. / N * np.ones((N, D)) * dvar\n",
    "        \n",
    "        # step3\n",
    "        dxmu2 = 2 * self.xmu * dsq\n",
    "        \n",
    "        # step2\n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "        dmu = -1 * np.sum(dxmu1 + dxmu2, axis=0)\n",
    "        \n",
    "        # step1\n",
    "        dx2 = 1. / N * np.ones((N, D)) * dmu\n",
    "        \n",
    "        # step0\n",
    "        dx = dx1 + dx2\n",
    "        \n",
    "        return dx\n",
    "\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.gamma -= self.lr * self.d_gamma\n",
    "        self.beta -= self.lr * self.d_beta\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ドロップアウト層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg :\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1 - self.dropout_ratio)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複数層を束ねるクラス(ネットワーククラス)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Layers:\n",
    "    def __init__(self, params):\n",
    "        unit_size_list = [params['input_size']]\n",
    "        unit_size_list.extend(params['hidden_layer_list'])\n",
    "        unit_size_list.append(params['output_size'])\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for i in range(1, len(unit_size_list)):\n",
    "            # 重みの初期化\n",
    "            init_W = np.random.randn(unit_size_list[i-1], unit_size_list[i])\n",
    "            init_b = np.zeros([1, unit_size_list[i]])\n",
    "            if params['init'] == 'gauss':\n",
    "                init_W *= 0.01\n",
    "            elif params['init'] == 'xavier':\n",
    "                init_W /= np.sqrt(unit_size_list[i-1])\n",
    "            else: # He\n",
    "                init_W = init_W / np.sqrt(unit_size_list[i-1]) * np.sqrt(2) \n",
    "                \n",
    "            # アフィン変換層（Wx + b）を追加する\n",
    "            self.layers['Affine' + str(i)] = Affine(init_W, init_b, params)\n",
    "            \n",
    "            # 最終層以外はバッチノーマリゼーション層と活性化関数層を追加する\n",
    "            if i < (len(unit_size_list)-1):\n",
    "                if params['batch_norm'] == True:\n",
    "                    self.layers['BatchNorm' + str(i)] = BatchNorm(0.001)\n",
    "                self.layers['Active' + str(i)] = Activation(params)\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "        # self.params['hidden_layer_num'] = len(unit_size_list)-1\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # forwardを繰り返す\n",
    "        # ソフトマックスを通さなくても答えは出るのでこれで予測とする \n",
    "        # argmaxでラベルを取れる\n",
    "        for layer in self.layers.values():\n",
    "            x =layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        # 正答率を小数点第二桁で出力する\n",
    "        y_pred = self.predict(x)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(t, axis=1)\n",
    "        data_size = x.shape[0]\n",
    "\n",
    "        correct_count = np.sum([y_true == y_pred]) \n",
    "        score = correct_count / data_size * 100\n",
    "\n",
    "        return round(score, 2)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    ## 拝借コード\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.layers['Affine1'].W)\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.layers['Affine1'].b)\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.layers['Affine2'].W)\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.layers['Affine2'].b)\n",
    "        \n",
    "        print(\"Numerical: {}\".format(grads['W1']) )\n",
    "        print(\"OreOre   : {}\".format(self.layers['Affine1'].W))\n",
    "        \n",
    "        return grads\n",
    "    ### まだ使えていない\n",
    "    \n",
    "    \n",
    "    def optimize(self, x, t):\n",
    "        \n",
    "        # forward \n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # backward\n",
    "        dout = self.lastLayer.backward(1)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # optimizeメソッドがある層は更新を行う\n",
    "        # AffineとBatchNorm層のみ行うはず\n",
    "        for layer in self.layers.values():\n",
    "            if hasattr(layer, \"optimize\"):\n",
    "                layer.optimize()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class DNN:\n",
    "    def __init__(self, init='gauss', iteration = 500, lr = 0.05,\n",
    "                 batch_mode = 'mini', act_func='relu',\n",
    "                 batch_size_rate = 0.1, hidden_layer_list = [5], optimizer='sgd',\n",
    "                 batch_norm=False, drop_out=False):\n",
    "        \"\"\" ハイパーパラメータ解説\n",
    "        init: 初期化方法\n",
    "            'he' : \n",
    "            'gauss' \n",
    "            'xavier'\n",
    "        lr : 学習率\n",
    "        batch_size: バッチサイズ\n",
    "            'batch' : フルサイズ\n",
    "            'mini' 0< x< 1: フルサイズ割合 0.1なら全体の0.1サイズ使用する\n",
    "            'online' : オンライン学習　１データのみ\n",
    "        hidden_layer_list : 隠れ層のリスト、層のユニットをリストで入力　例[2, 3]　ユニット数２、ユニット数３の隠れ層\n",
    "        optimizer : 勾配の更新手法\n",
    "            'sgd' : 確率的勾配降下法\n",
    "            'adam': \n",
    "            'adagrad':\n",
    "        act_func: 活性化関数の名前　パラメータ名が微妙\n",
    "            'relu' : ReLU関数\n",
    "            'tanh' : tanh\n",
    "            'sigmoid' : シグモイド関数\n",
    "        \"\"\"\n",
    "        self.params = {}\n",
    "        self.params['iteration'] = iteration\n",
    "        self.params['init'] = init\n",
    "        self.params['lr'] = lr\n",
    "        self.params['batch_mode'] = batch_mode # データ数が決まったらそれに基づいて変更する\n",
    "        self.params['batch_size_rate'] = batch_size_rate # ミニバッチ法のときのみ使用する\n",
    "        self.params['hidden_layer_list'] = hidden_layer_list\n",
    "        self.params['optimizer'] = optimizer\n",
    "        self.params['batch_norm'] = batch_norm\n",
    "        self.params['drop_out'] = drop_out\n",
    "        self.params['act_func'] = act_func\n",
    "        \n",
    "    def train(self, X, y, params={}):\n",
    "        # 入力パラメータがあれば更新する\n",
    "        for key in params:\n",
    "                self.params[key] = params[key]\n",
    "        \n",
    "        # 正規化　必要？\n",
    "        X = X / 255.0\n",
    "        \n",
    "        # 訓練とテストデータに分割\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "        self.params['data_size'] = X_train.shape[0]\n",
    "        self.params['input_size'] = X_train.shape[1]\n",
    "        self.params['output_size'] = y_train.shape[1]\n",
    "\n",
    "        \n",
    "        # コストや正答率の学習曲線を引くためのリストを用意\n",
    "        past_train_costs = []\n",
    "        past_test_costs = []\n",
    "        past_train_accuracy = []\n",
    "        past_test_accuracy = []\n",
    "        \n",
    "        # 初期化\n",
    "        # 重み初期化\n",
    "        # バッチサイズの設定\n",
    "        if self.params['batch_mode'] == 'batch':\n",
    "            self.params['batch_size'] = self.params['data_size']\n",
    "        elif self.params['batch_mode'] == 'mini':\n",
    "            self.params['batch_size'] = int(self.params['data_size']  * self.params['batch_size_rate'] ) \n",
    "        else:\n",
    "            self.params['batch_size'] = 1\n",
    "        # 隠れ層やレイヤーインスタンス生成\n",
    "        self.params['layer'] = Layers(self.params)\n",
    "        \n",
    "        \n",
    "        # 何イテレーションで1エポックか\n",
    "        epoch_per_i = int(self.params['data_size'] / self.params['batch_size'])\n",
    "        \n",
    "        ##################\n",
    "        # 最急降下法での学習\n",
    "        ##################\n",
    "        for i in range(self.params['iteration']):\n",
    "            \n",
    "            # 学習に使用するデータをサンプリング\n",
    "            choice_index = np.random.choice(self.params['data_size'], self.params['batch_size'])\n",
    "            X_batch, y_batch = X_train[choice_index], y_train[choice_index]\n",
    "            \n",
    "            # 誤差逆伝播法によって勾配を求め、値を更新\n",
    "            self.params['layer'].optimize(X_batch, y_batch)\n",
    "            \n",
    "            # 1エポックごとに正答率とコストを算出して保存する\n",
    "            if i % epoch_per_i == 0:              \n",
    "                past_train_accuracy.append(self.params['layer'].accuracy(X_train, y_train))\n",
    "                past_test_accuracy.append(self.params['layer'].accuracy(X_test, y_test))\n",
    "                \n",
    "                past_train_costs.append(self.params['layer'].loss(X_train, y_train))\n",
    "                past_test_costs.append(self.params['layer'].loss(X_test, y_test))\n",
    "            \n",
    "        return past_train_accuracy, past_test_accuracy, past_train_costs, past_test_costs \n",
    "    \n",
    "    def plot_learning_curve(self, X, y, metrics='acc', params={}): \n",
    "        past_train_accuracy, past_test_accuracy, past_train_costs, past_test_costs = self.train(X, y, params)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        # count_epoch = self.params['iteration'] // self.params['data_size'] + 1\n",
    "        if metrics == 'cost':\n",
    "            plt.plot(past_train_costs, color='orange', label='train')\n",
    "            plt.plot(past_test_costs, color='lime', label='test')\n",
    "            plt.ylabel(\"cost\", fontsize=15)\n",
    "            print(\"last train cost is {}\".format(past_train_costs[-1]))\n",
    "            print(\"last test cost is {}\".format(past_test_costs[-1]))\n",
    "        else:\n",
    "            #plt.plot(np.array(past_train_accuracy), color='r')\n",
    "            plt.plot(past_train_accuracy, color='orange', label='train')\n",
    "            plt.plot(past_test_accuracy, color='lime', label='test')\n",
    "            plt.ylabel(\"accuracy\", fontsize=15)\n",
    "            print(\"last train accuracy is {}\".format(past_train_accuracy[-1]))\n",
    "            print(\"last test accuracy is {}\".format(past_test_accuracy[-1]))\n",
    "            plt.ylim(-0.5, 100.5)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title('Learning Curve', fontsize=20)\n",
    "        plt.xlabel(\"iteration[epoch]\", fontsize=15)\n",
    "        \n",
    "    # 現在のパラメータで予測値を確率かラベルで出力する。\n",
    "    def predict(self, X, probability=False):\n",
    "        predict = self.params['layer'].predict(X)\n",
    "        predict_proba = softmax(predict)\n",
    "        if probability== True:\n",
    "            return predict_proba\n",
    "        else:\n",
    "            return np.argmax(predict_proba, axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(iteration=10000, optimizer='adam', \n",
    "            hidden_layer_list = [100, 100, 100, 100, 100, 100, 100], batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last train accuracy is 66.5\n",
      "last test accuracy is 37.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102c807f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {'optimizer': 'adam',\n",
    "         'batch_mode' : 'mini',\n",
    "         'init': 'he',\n",
    "         'lr': 0.01}\n",
    "\n",
    "#past_train_accuracy, past_test_accuracy = model.train(X,y, params)\n",
    "# model.plot_learning_curve(X,y, 'cost', params)\n",
    "\n",
    "model.plot_learning_curve(X,y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.plot_learning_curve(X,y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出用ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X_sub = test_df\n",
    "X_sub = np.array(X_sub)\n",
    "\n",
    "Y_pred = model.predict(X_sub)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "       \"ImageId\": np.array(test_df.index) + 1,\n",
    "       \"Label\": Y_pred\n",
    "   })\n",
    "\n",
    "submission.to_csv(\"./submission_002.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
